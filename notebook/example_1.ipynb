{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Character Moral Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "import json\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turning the JSON file into pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, read the JSON file\n",
    "with open(\"../data/dialogue.json\", \"r\") as file:\n",
    "    dialogue_dict = json.load(file)\n",
    "\n",
    "# Create a list to store all dialogues\n",
    "dialogue_list = []\n",
    "\n",
    "# Handle the nested structure correctly\n",
    "for movie, data in dialogue_dict.items():\n",
    "    # Check if data is a dictionary or list\n",
    "    if isinstance(data, dict):\n",
    "        # If it's a dictionary, iterate through characters\n",
    "        for character, lines in data.items():\n",
    "            if isinstance(lines, list):\n",
    "                for line in lines:\n",
    "                    dialogue_list.append({\n",
    "                        'movie': movie,\n",
    "                        'character': character,\n",
    "                        'dialogue': line\n",
    "                    })\n",
    "    elif isinstance(data, list):\n",
    "        # If it's directly a list of lines\n",
    "        for line in data:\n",
    "            dialogue_list.append({\n",
    "                'movie': movie,\n",
    "                'dialogue': line\n",
    "            })\n",
    "\n",
    "# Create the DataFrame\n",
    "dialogue_df = pd.DataFrame(dialogue_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turning the json into python dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the JSON file\n",
    "with open(\"../data/dialogue.json\", \"r\") as file:\n",
    "    raw_dialogue = json.load(file)\n",
    "\n",
    "# Create a nested dictionary structure\n",
    "dialogue = {}\n",
    "\n",
    "for movie, data in raw_dialogue.items():\n",
    "    # Initialize movie dictionary if not exists\n",
    "    if movie not in dialogue:\n",
    "        dialogue[movie] = {}\n",
    "        \n",
    "    # If data is a dictionary (contains character information)\n",
    "    if isinstance(data, dict):\n",
    "        for character, lines in data.items():\n",
    "            if isinstance(lines, list):\n",
    "                dialogue[movie][character] = lines\n",
    "    # If data is a list (direct dialogues without character info)\n",
    "    elif isinstance(data, list):\n",
    "        dialogue[movie]['unknown'] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>character</th>\n",
       "      <th>dialogue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10 Things I Hate About You</td>\n",
       "      <td>KAT</td>\n",
       "      <td>Leave it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10 Things I Hate About You</td>\n",
       "      <td>KAT</td>\n",
       "      <td>Why didn't we just read the Hardy Boys?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10 Things I Hate About You</td>\n",
       "      <td>KAT</td>\n",
       "      <td>This book is about a guy and his fishing habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10 Things I Hate About You</td>\n",
       "      <td>KAT</td>\n",
       "      <td>(continuing) Frankly, I'm baffled as to why w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10 Things I Hate About You</td>\n",
       "      <td>KAT</td>\n",
       "      <td>I guess the school board thinks because Hemin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        movie character  \\\n",
       "0  10 Things I Hate About You       KAT   \n",
       "1  10 Things I Hate About You       KAT   \n",
       "2  10 Things I Hate About You       KAT   \n",
       "3  10 Things I Hate About You       KAT   \n",
       "4  10 Things I Hate About You       KAT   \n",
       "\n",
       "                                            dialogue  \n",
       "0                                          Leave it   \n",
       "1           Why didn't we just read the Hardy Boys?   \n",
       "2   This book is about a guy and his fishing habi...  \n",
       "3   (continuing) Frankly, I'm baffled as to why w...  \n",
       "4   I guess the school board thinks because Hemin...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogue_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "character\n",
       "KAT           219\n",
       "PATRICK       187\n",
       "BIANCA        131\n",
       "CAMERON       105\n",
       "MICHAEL        89\n",
       "JOEY           62\n",
       "WALTER         54\n",
       "MANDELLA       40\n",
       "MISS PERKY     24\n",
       "MRS            12\n",
       "CHASTITY       11\n",
       "SHARON         11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogue_df[dialogue_df[\"movie\"]== \"10 Things I Hate About You\"][\"character\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading moral foundations dictionary\n",
    "moral_dict = pd.read_csv(\"../data/mfd_v2.csv\")\n",
    "\n",
    "# Convert DataFrame to dictionary for O(1) lookup\n",
    "moral_word_dict = dict(zip(moral_dict['word'].str.lower(), moral_dict['category']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Movies 1134\n",
      "Number of characters 12853\n",
      "Number of dialogues 788415\n"
     ]
    }
   ],
   "source": [
    "# Let's count the number of characters we have in the dataset\n",
    "count = 0\n",
    "for movie, data in dialogue.items():\n",
    "    count += len(data)\n",
    "print(\"Number of Movies\", len(dialogue))\n",
    "print(\"Number of characters\", count)\n",
    "print(\"Number of dialogues\", dialogue_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Things I Hate About You\n",
      "12\n",
      "12 and Holding\n",
      "12 Monkeys\n",
      "12 Years a Slave\n",
      "127 Hours\n",
      "1492: Conquest of Paradise\n",
      "15 Minutes\n",
      "17 Again\n",
      "187\n",
      "2001: A Space Odyssey\n",
      "2012\n",
      "28 Days Later\n",
      "30 Minutes or Less\n",
      "42\n",
      "44 Inch Chest\n",
      "48 Hrs.\n",
      "50-50\n",
      "500 Days of Summer\n",
      "8MM\n",
      "A Few Good Men\n",
      "A Most Violent Year\n",
      "A Prayer Before Dawn\n",
      "A Quiet Place\n",
      "A Scanner Darkly\n",
      "A Serious Man\n",
      "Above the Law\n",
      "Absolute Power\n",
      "Abyss, The\n",
      "Ace Ventura: Pet Detective\n",
      "Adaptation\n",
      "Adjustment Bureau, The\n",
      "Adventures of Buckaroo Banzai Across the Eighth Dimension, The\n",
      "Affliction\n",
      "After School Special\n",
      "After.Life\n",
      "Agnes of God\n",
      "Air Force One\n",
      "Airplane\n",
      "Airplane 2: The Sequel\n",
      "Ali\n",
      "Alien\n",
      "Alien 3\n",
      "Alien Nation\n",
      "Alien vs. Predator\n",
      "Aliens\n",
      "All About Eve\n",
      "All About Steve\n",
      "All the King's Men\n",
      "All the President's Men\n",
      "Almost Famous\n",
      "Alone in the Dark\n",
      "Amadeus\n",
      "Amelia\n",
      "American Beauty\n",
      "American Gangster\n",
      "American Graffiti\n",
      "American History X\n",
      "American Hustle\n",
      "American Milkshake\n",
      "American Pie\n",
      "American President, The\n",
      "American Psycho\n",
      "American Shaolin: King of Kickboxers II\n",
      "American Sniper\n",
      "American Splendor\n",
      "American Werewolf in London\n",
      "American, The\n",
      "Amityville Asylum, The\n",
      "Amour\n",
      "An Education\n",
      "Analyze That\n",
      "Analyze This\n",
      "Anastasia\n",
      "Angel Eyes\n",
      "Anna Karenina\n",
      "Annie Hall\n",
      "Anniversary Party, The\n",
      "Anonymous\n",
      "Antitrust\n",
      "Antz\n",
      "Apartment, The\n",
      "Apocalypse Now\n",
      "Apollo 13\n",
      "April Fool's Day\n",
      "Apt Pupil\n",
      "Arbitrage\n",
      "Arcade\n",
      "Arctic Blue\n",
      "Argo\n",
      "Army of Darkness\n",
      "Arsenic and Old Lace\n",
      "Arthur\n",
      "As Good As It Gets\n",
      "Assassins\n",
      "Assignment, The\n",
      "At First Sight\n",
      "August: Osage County\n",
      "Austin Powers - International Man of Mystery\n",
      "Austin Powers - The Spy Who Shagged Me\n",
      "Authors Anonymous\n",
      "Autumn in New York\n",
      "Avatar\n",
      "Avengers, The\n",
      "Avengers, The (2012)\n",
      "Avventura, L' (The Adventure)\n",
      "Awakenings\n",
      "Babel\n",
      "Bachelor Party\n",
      "Bachelor Party, The\n",
      "Back-up Plan, The\n",
      "Backdraft\n",
      "Bad Boys\n",
      "Bad Country\n",
      "Bad Day at Black Rock\n",
      "Bad Dreams\n",
      "Bad Lieutenant\n",
      "Bad Santa\n",
      "Bad Teacher\n",
      "Badlands\n",
      "Bamboozled\n",
      "Barry Lyndon\n",
      "Barton Fink\n",
      "Basic\n",
      "Basic Instinct\n",
      "Basquiat\n",
      "Batman\n",
      "Batman 2\n",
      "Battle of Algiers, The\n",
      "Battle of Shaker Heights, The\n",
      "Battle: Los Angeles\n",
      "Beach, The\n",
      "Bean\n",
      "Beasts of No Nation\n",
      "Beasts of the Southern Wild\n",
      "Beauty and the Beast\n",
      "Beavis and Butt-head Do America\n",
      "Beginners\n",
      "Being Human\n",
      "Being John Malkovich\n",
      "Being There\n",
      "Believer, The\n",
      "Belle\n",
      "Beloved\n",
      "Best Exotic Marigold Hotel, The\n",
      "Big\n",
      "Big Blue, The\n",
      "Big Eyes\n",
      "Big Fish\n",
      "Big Lebowski, The\n",
      "Big Sick, The\n",
      "Big White, The\n",
      "Birdman\n",
      "Birds, The\n",
      "Birthday Girl\n",
      "Black Dahlia, The\n",
      "Black Panther\n",
      "Black Rain\n",
      "Black Snake Moan\n",
      "Black Swan\n",
      "BlacKkKlansman\n",
      "Blade\n",
      "Blade II\n",
      "Blade Runner\n",
      "Blade: Trinity\n",
      "Blast from the Past, The\n",
      "Blind Side, The\n",
      "Bling Ring, The\n",
      "Blood and Wine\n",
      "Blood Simple\n",
      "Blow\n",
      "Blue Valentine\n",
      "Blue Velvet\n",
      "Body Heat\n",
      "Body of Evidence\n",
      "Bodyguard\n",
      "Bones\n",
      "Bonfire of the Vanities\n",
      "Bonnie and Clyde\n",
      "Book of Eli, The\n",
      "Boondock Saints 2: All Saints Day\n",
      "Boondock Saints, The\n",
      "Bottle Rocket\n",
      "Bound\n",
      "Bounty Hunter, The\n",
      "Bourne Identity, The\n",
      "Bourne Ultimatum, The\n",
      "Box, The\n",
      "Boxtrolls, The\n",
      "Boyhood\n",
      "Braveheart\n",
      "Brazil\n",
      "Break\n",
      "Breakdown\n",
      "Breakfast Club, The\n",
      "Breaking Away\n",
      "Brick\n",
      "Bridesmaids\n",
      "Bringing Out the Dead\n",
      "Broadcast News\n",
      "Broken Arrow\n",
      "Broken Embraces\n",
      "Brothers Bloom, The\n",
      "Bruce Almighty\n",
      "Buffy the Vampire Slayer\n",
      "Bull Durham\n",
      "Buried\n",
      "Burlesque\n",
      "Burn After Reading\n",
      "Burning Annie\n",
      "Butterfly Effect, The\n",
      "Cable Guy\n",
      "Candle to Water\n",
      "Capote\n",
      "Carrie\n",
      "Cars 2\n",
      "Case 39\n",
      "Casino\n",
      "Cast Away\n",
      "Catch Me If You Can\n",
      "Cecil B. Demented\n",
      "Cedar Rapids\n",
      "Cell, The\n",
      "Cellular\n",
      "Change-Up, The\n",
      "Changeling\n",
      "Chaos\n",
      "Charade\n",
      "Charlie's Angels\n",
      "Chasing Amy\n",
      "Chasing Sleep\n",
      "Cherry Falls\n",
      "Chinatown\n",
      "Christ Complex\n",
      "Chronicle\n",
      "Chronicles of Narnia: The Lion, the Witch and the Wardrobe\n",
      "Cider House Rules, The\n",
      "Cincinnati Kid, The\n",
      "Cinema Paradiso\n",
      "Cirque du Freak: The Vampire's Assistant\n",
      "Citizen Kane\n",
      "City of Joy\n",
      "Clash of the Titans\n",
      "Clerks\n",
      "Cliffhanger\n",
      "Cobb\n",
      "Coco\n",
      "Code of Silence\n",
      "Cold Mountain\n",
      "Collateral Damage\n",
      "Colombiana\n",
      "Color of Night\n",
      "Commando\n",
      "Conan the Barbarian\n",
      "Confessions of a Dangerous Mind\n",
      "Confidence\n",
      "Cooler, The\n",
      "Copycat\n",
      "Coraline\n",
      "Coriolanus\n",
      "Cradle 2 the Grave\n",
      "Crank\n",
      "Crash\n",
      "Crazy, Stupid, Love\n",
      "Crazylove\n",
      "Creation\n",
      "Crime Spree\n",
      "Croods, The\n",
      "Crouching Tiger, Hidden Dragon\n",
      "Croupier\n",
      "Crow Salvation, The\n",
      "Crow, The\n",
      "Cruel Intentions\n",
      "Crying Game\n",
      "Cube\n",
      "Curious Case of Benjamin Button, The\n",
      "Custody\n",
      "Dallas Buyers Club\n",
      "Damned United, The\n",
      "Dances with Wolves\n",
      "Danish Girl, The\n",
      "Dark City\n",
      "Dark Knight Rises, The\n",
      "Dark Star\n",
      "Darkman\n",
      "Date Night\n",
      "Dave Barry's Complete Guide to Guys\n",
      "Day of the Dead\n",
      "Day the Clown Cried, The\n",
      "Day the Earth Stood Still, The\n",
      "Days of Heaven\n",
      "Dead Poets Society\n",
      "Deadpool\n",
      "Dear White People\n",
      "Death at a Funeral\n",
      "Death to Smoochy\n",
      "Debt, The\n",
      "Deception\n",
      "Deep Cover\n",
      "Deep Rising\n",
      "Deer Hunter, The\n",
      "Defiance\n",
      "Departed, The\n",
      "Descendants, The\n",
      "Despicable Me 2\n",
      "Detroit Rock City\n",
      "Devil in a Blue Dress\n",
      "Devil Wears Prada, The\n",
      "Devil's Advocate\n",
      "Die Hard\n",
      "Die Hard 2\n",
      "Diner\n",
      "Distinguished Gentleman, The\n",
      "Disturbia\n",
      "Django Unchained\n",
      "Do The Right Thing\n",
      "Dog Day Afternoon\n",
      "Donnie Brasco\n",
      "Doors, The\n",
      "Double Indemnity\n",
      "Drag Me to Hell\n",
      "Dragonslayer\n",
      "Drive\n",
      "Drive Angry\n",
      "Drop Dead Gorgeous\n",
      "Dry White Season, A\n",
      "Duck Soup\n",
      "Dumb and Dumber\n",
      "Dune\n",
      "Eagle Eye\n",
      "Eastern Promises\n",
      "Easy A\n",
      "Ed TV\n",
      "Ed Wood\n",
      "Edward Scissorhands\n",
      "Eight Legged Freaks\n",
      "Election\n",
      "Elephant Man, The\n",
      "Elizabeth: The Golden Age\n",
      "Enemy of the State\n",
      "English Patient, The\n",
      "Enough\n",
      "Entrapment\n",
      "Erik the Viking\n",
      "Erin Brockovich\n",
      "Escape From L.A.\n",
      "Escape From New York\n",
      "Eternal Sunshine of the Spotless Mind\n",
      "Even Cowgirls Get the Blues\n",
      "Event Horizon\n",
      "Evil Dead II: Dead by Dawn\n",
      "Ex Machina\n",
      "Excalibur\n",
      "eXistenZ\n",
      "Extract\n",
      "Fabulous Baker Boys, The\n",
      "Face Off\n",
      "Fair Game\n",
      "Family Man, The\n",
      "Fantastic Four\n",
      "Fantastic Mr Fox\n",
      "Fargo\n",
      "Fast Times at Ridgemont High\n",
      "Fatal Instinct\n",
      "Fault in Our Stars, The\n",
      "Fear and Loathing in Las Vegas\n",
      "Feast\n",
      "Ferris Bueller's Day Off\n",
      "Field of Dreams\n",
      "Fifth Element, The\n",
      "Fight Club\n",
      "Fighter, The\n",
      "Final Destination\n",
      "Final Destination 2\n",
      "Finding Nemo\n",
      "Five Easy Pieces\n",
      "Flash Gordon\n",
      "Flight\n",
      "Flintstones, The\n",
      "Forrest Gump\n",
      "Four Feathers\n",
      "Four Rooms\n",
      "Foxcatcher\n",
      "Fracture\n",
      "Frances\n",
      "Frankenstein\n",
      "Frankenweenie\n",
      "Freaked\n",
      "Freddy vs. Jason\n",
      "French Connection, The\n",
      "Frequency\n",
      "Friday the 13th\n",
      "Friday the 13th Part VIII: Jason Takes Manhattan\n",
      "Fright Night\n",
      "Fright Night (1985)\n",
      "From Dusk Till Dawn\n",
      "From Here to Eternity\n",
      "Frozen\n",
      "Frozen (Disney)\n",
      "Frozen River\n",
      "Fruitvale Station\n",
      "Fugitive, The\n",
      "Funny People\n",
      "G.I. Jane\n",
      "G.I. Joe: The Rise of Cobra\n",
      "Game 6\n",
      "Game, The\n",
      "Gamer\n",
      "Gandhi\n",
      "Gang Related\n",
      "Gangs of New York\n",
      "Garden State\n",
      "Gattaca\n",
      "Get Carter\n",
      "Get Low\n",
      "Get on Up\n",
      "Get Out\n",
      "Getaway, The\n",
      "Ghost\n",
      "Ghost and the Darkness, The\n",
      "Ghost Rider\n",
      "Ghost Ship\n",
      "Ghost World\n",
      "Ghostbusters\n",
      "Ghostbusters 2\n",
      "Girl with the Dragon Tattoo, The\n",
      "Gladiator\n",
      "Glengarry Glen Gross\n",
      "Go\n",
      "Godfather\n",
      "Godfather Part II\n",
      "Godfather Part III, The\n",
      "Gods and Monsters\n",
      "Godzilla\n",
      "Gone Baby Gone\n",
      "Gone in 60 Seconds\n",
      "Good Girl, The\n",
      "Good Will Hunting\n",
      "Grabbers\n",
      "Graduate, The\n",
      "Gran Torino\n",
      "Grand Hotel\n",
      "Grand Theft Parsons\n",
      "Grapes of Wrath, The\n",
      "Gravity\n",
      "Great Gatsby, The\n",
      "Green Mile, The\n",
      "Gremlins\n",
      "Gremlins 2\n",
      "Grifters, The\n",
      "Grosse Point Blank\n",
      "Groundhog Day\n",
      "Grudge, The\n",
      "Guardians of the Galaxy Vol 2\n",
      "Hackers\n",
      "Hall Pass\n",
      "Halloween\n",
      "Halloween: The Curse of Michael Myers\n",
      "Hancock\n",
      "Hangover, The\n",
      "Hanna\n",
      "Hannah and Her Sisters\n",
      "Hannibal\n",
      "Happy Birthday, Wanda June\n",
      "Happy Feet\n",
      "Hard Rain\n",
      "Hard to Kill\n",
      "Harold and Kumar Go to White Castle\n",
      "Haunting, The\n",
      "He's Just Not That Into You\n",
      "Heat\n",
      "Heathers\n",
      "Heavenly Creatures\n",
      "Heavy Metal\n",
      "Hebrew Hammer, The\n",
      "Heist\n",
      "Hellbound: Hellraiser II\n",
      "Hellboy\n",
      "Hellboy 2: The Golden Army\n",
      "Hellraiser\n",
      "Hellraiser 3: Hell on Earth\n",
      "Hellraiser: Deader\n",
      "Hellraiser: Hellseeker\n",
      "Help, The\n",
      "Henry Fool\n",
      "Henry's Crime\n",
      "Her\n",
      "Hesher\n",
      "High Fidelity\n",
      "Highlander\n",
      "Highlander: Endgame\n",
      "Hills Have Eyes, The\n",
      "His Girl Friday\n",
      "Hitchcock\n",
      "Hitchhiker's Guide to the Galaxy, The\n",
      "Hollow Man\n",
      "Honeydripper\n",
      "Horrible Bosses\n",
      "Horse Whisperer, The\n",
      "Hospital, The\n",
      "Hostage\n",
      "Hot Tub Time Machine\n",
      "Hotel Rwanda\n",
      "House of 1000 Corpses\n",
      "How to Train Your Dragon\n",
      "How to Train Your Dragon 2\n",
      "Hudson Hawk\n",
      "Hudsucker Proxy, The\n",
      "Human Nature\n",
      "Hunt for Red October, The\n",
      "Hurt Locker, The\n",
      "I Am Number Four\n",
      "I am Sam\n",
      "I Love You Phillip Morris\n",
      "I Spit on Your Grave\n",
      "I Still Know What You Did Last Summer\n",
      "I'll Do Anything\n",
      "I, Robot\n",
      "Ice Storm, The\n",
      "Ides of March, The\n",
      "Imaginarium of Doctor Parnassus, The\n",
      "In the Bedroom\n",
      "In the Loop\n",
      "Inception\n",
      "Independence Day\n",
      "Indiana Jones and the Last Crusade\n",
      "Indiana Jones and the Raiders of the Lost Ark\n",
      "Indiana Jones and the Temple of Doom\n",
      "Indiana Jones IV\n",
      "Informant, The\n",
      "Inglourious Basterds\n",
      "Insider, The\n",
      "Insidious\n",
      "Insomnia\n",
      "Interstellar\n",
      "Interview with the Vampire\n",
      "Into the Wild\n",
      "Into the Woods\n",
      "Intolerable Cruelty\n",
      "Inventing the Abbotts\n",
      "Invention of Lying, The\n",
      "Invictus\n",
      "Iron Lady, The\n",
      "Island, The\n",
      "It\n",
      "It's a Wonderful Life\n",
      "It's Complicated\n",
      "Italian Job, The\n",
      "Jacket, The\n",
      "Jackie Brown\n",
      "Jacob's Ladder\n",
      "Jane Eyre\n",
      "Jason X\n",
      "Jaws\n",
      "Jaws 2\n",
      "Jay and Silent Bob Strike Back\n",
      "Jennifer Eight\n",
      "Jennifer's Body\n",
      "Jerry Maguire\n",
      "Jeux Interdits\n",
      "JFK\n",
      "Jimmy and Judy\n",
      "John Q\n",
      "John Wick\n",
      "Joker\n",
      "Judge Dredd\n",
      "Juno\n",
      "Jurassic Park\n",
      "Jurassic Park III\n",
      "Jurassic Park: The Lost World\n",
      "Kafka\n",
      "Kalifornia\n",
      "Kids\n",
      "Kids Are All Right, The\n",
      "Kill Your Darlings\n",
      "Killing Zoe\n",
      "King Kong\n",
      "King of Comedy, The\n",
      "King's Speech, The\n",
      "Kingdom, The\n",
      "Klute\n",
      "Knocked Up\n",
      "Kramer vs Kramer\n",
      "Kundun\n",
      "Kung Fu Panda\n",
      "L.A. Confidential\n",
      "La La Land\n",
      "Labor of Love\n",
      "Ladykillers, The\n",
      "Lake Placid\n",
      "Larry Crowne\n",
      "Last Boy Scout, The\n",
      "Last Chance Harvey\n",
      "Last Flight, The\n",
      "Last of the Mohicans, The\n",
      "Last Samurai, The\n",
      "Last Station, The\n",
      "Last Tango in Paris\n",
      "Law Abiding Citizen\n",
      "Le Diable par la Queue\n",
      "Leaving Las Vegas\n",
      "Legion\n",
      "LEGO Movie, The\n",
      "Les Miserables\n",
      "Les Tontons Flingueurs\n",
      "Leviathan\n",
      "Liar Liar\n",
      "Life\n",
      "Life As A House\n",
      "Life of David Gale, The\n",
      "Life of Pi\n",
      "Light Sleeper\n",
      "Limey, The\n",
      "Limitless\n",
      "Lincoln\n",
      "Lincoln Lawyer, The\n",
      "Little Athens\n",
      "Little Men\n",
      "Little Nicky\n",
      "Living in Oblivion\n",
      "Lock, Stock and Two Smoking Barrels\n",
      "Logan\n",
      "Logan's Run\n",
      "Lone Star\n",
      "Long Kiss Goodnight, The\n",
      "Looper\n",
      "Lord of Illusions\n",
      "Lord of the Rings: Fellowship of the Ring, The\n",
      "Lord of the Rings: Return of the King\n",
      "Lord of the Rings: The Two Towers\n",
      "Lord of War\n",
      "Losers, The\n",
      "Lost Highway\n",
      "Lost in Translation\n",
      "Love and Basketball\n",
      "Machete\n",
      "Machine Gun Preacher\n",
      "Mad Max 2: The Road Warrior\n",
      "Magnolia\n",
      "Majestic, The (The Bijou)\n",
      "Major League\n",
      "Malcolm X\n",
      "Malibu's Most Wanted\n",
      "Man in the Iron Mask\n",
      "Man On Fire\n",
      "Man on the Moon\n",
      "Man Trouble\n",
      "Man Who Knew Too Much, The\n",
      "Man Who Wasn't There, The\n",
      "Manhattan Murder Mystery\n",
      "Manhunter\n",
      "Margaret\n",
      "Margin Call\n",
      "Margot at the Wedding\n",
      "Mariachi, El\n",
      "Martha Marcy May Marlene\n",
      "Martian, The\n",
      "Marty\n",
      "Mask, The\n",
      "Master and Commander\n",
      "Master, The\n",
      "Matrix, The\n",
      "Max Payne\n",
      "Mean Streets\n",
      "Mechanic, The\n",
      "Meet Joe Black\n",
      "Megamind\n",
      "Memento\n",
      "Men in Black\n",
      "Men in Black 3\n",
      "Men Who Stare at Goats, The\n",
      "Metro\n",
      "Miami Vice\n",
      "Midnight Cowboy\n",
      "Midnight Express\n",
      "Midnight in Paris\n",
      "Mighty Joe Young\n",
      "Mighty Morphin Power Rangers: The Movie\n",
      "Milk\n",
      "Mimic\n",
      "Mini's First Time\n",
      "Minority Report\n",
      "Miracle Worker, The\n",
      "Mirrors\n",
      "Misery\n",
      "Mission Impossible\n",
      "Mission Impossible II\n",
      "Mission to Mars\n",
      "Moneyball\n",
      "Monkeybone\n",
      "Monte Carlo\n",
      "Moon\n",
      "Moonrise Kingdom\n",
      "Moonstruck\n",
      "Mr Blandings Builds His Dream House\n",
      "Mr Brooks\n",
      "Mrs. Brown\n",
      "Mud\n",
      "Mulholland Drive\n",
      "Mumford\n",
      "Mummy, The\n",
      "Music of the Heart\n",
      "Mute Witness\n",
      "My Best Friend's Wedding\n",
      "My Girl\n",
      "My Mother Dreams the Satan's Disciples in New York\n",
      "My Week with Marilyn\n",
      "Mystery Men\n",
      "Nashville\n",
      "Natural Born Killers\n",
      "Never Been Kissed\n",
      "New York Minute\n",
      "Newsies\n",
      "Next\n",
      "Next Friday\n",
      "Next Three Days, The\n",
      "Ni vu ni connu\n",
      "Nick of Time\n",
      "Nightmare Before Christmas, The\n",
      "Nightmare on Elm Street, A\n",
      "Nightmare on Elm Street: The Final Chapter\n",
      "Nine\n",
      "Nines, The\n",
      "Ninja Assassin\n",
      "Ninotchka\n",
      "No Country for Old Men\n",
      "No Strings Attached\n",
      "Notting Hill\n",
      "Nurse Betty\n",
      "Oblivion\n",
      "Observe and Report\n",
      "Obsessed\n",
      "Ocean's Eleven\n",
      "Ocean's Twelve\n",
      "Office Space\n",
      "One Flew Over the Cuckoo's Nest\n",
      "Only God Forgives\n",
      "Ordinary People\n",
      "Orgy of the Dead\n",
      "Orphan\n",
      "Other Boleyn Girl, The\n",
      "Out of Sight\n",
      "Pacifier, The\n",
      "Pandorum\n",
      "Panic Room\n",
      "ParaNorman\n",
      "Pariah\n",
      "Passengers\n",
      "Patriot, The\n",
      "Paul\n",
      "Pearl Harbor\n",
      "Peeping Tom\n",
      "Peggy Sue Got Married\n",
      "Perfect Creature\n",
      "Perfect World, A\n",
      "Perks of Being a Wallflower, The\n",
      "Pet Sematary\n",
      "Pet Sematary II\n",
      "Petulia\n",
      "Philadelphia\n",
      "Phone Booth\n",
      "Pi\n",
      "Pianist, The\n",
      "Piano, The\n",
      "Pineapple Express\n",
      "Pirates of the Caribbean\n",
      "Pirates of the Caribbean: Dead Man's Chest\n",
      "Pitch Black\n",
      "Planet of the Apes, The\n",
      "Platoon\n",
      "Pleasantville\n",
      "Point Break\n",
      "Postman, The\n",
      "Power of One, The\n",
      "Precious\n",
      "Predator\n",
      "Prestige, The\n",
      "Pretty Woman\n",
      "Pretty Woman (final script)\n",
      "Pride and Prejudice\n",
      "Priest\n",
      "Princess Bride, The\n",
      "Private Life of Sherlock Holmes, The\n",
      "Producer, The\n",
      "Program, The\n",
      "Prom Night\n",
      "Prometheus\n",
      "Prophecy, The\n",
      "Proposal, The\n",
      "Psycho\n",
      "Public Enemies\n",
      "Pulp Fiction\n",
      "Punch-Drunk Love\n",
      "Purple Rain\n",
      "Quantum Project\n",
      "Queen of the Damned\n",
      "Queen, The\n",
      "Rachel Getting Married\n",
      "Raging Bull\n",
      "Raising Arizona\n",
      "Rambling Rose\n",
      "Rambo: First Blood II: The Mission\n",
      "Reader, The\n",
      "Real Genius\n",
      "Rear Window\n",
      "Rebel Without A Cause\n",
      "Red Planet\n",
      "Red Riding Hood\n",
      "Reindeer Games\n",
      "Relic, The\n",
      "Remember Me\n",
      "Replacements, The\n",
      "Repo Man\n",
      "Reservoir Dogs\n",
      "Resident Evil\n",
      "Revenant, The\n",
      "Revolutionary Road\n",
      "Ringu\n",
      "Rise of the Guardians\n",
      "Rise of the Planet of the Apes\n",
      "RKO 281\n",
      "Road, The\n",
      "Robin Hood: Prince of Thieves\n",
      "Rock, The\n",
      "RocknRolla\n",
      "Rocky\n",
      "Rocky Horror Picture Show, The\n",
      "Ronin\n",
      "Room\n",
      "Roommate, The\n",
      "Roughshod\n",
      "Ruins, The\n",
      "Runaway Bride\n",
      "Rush\n",
      "Rush Hour\n",
      "Rush Hour 2\n",
      "Rust and Bone\n",
      "S. Darko\n",
      "Saint, The\n",
      "Salton Sea, The\n",
      "Sandlot Kids, The\n",
      "Save the Last Dance\n",
      "Saving Mr. Banks\n",
      "Saving Private Ryan\n",
      "Saw\n",
      "Scarface\n",
      "Scary Movie 2\n",
      "Schindler's List\n",
      "Scott Pilgrim vs the World\n",
      "Scream\n",
      "Scream 2\n",
      "Scream 3\n",
      "Se7en\n",
      "Searchers, The\n",
      "Secret Life of Walter Mitty, The\n",
      "Semi-Pro\n",
      "Sense and Sensibility\n",
      "Serenity\n",
      "Serial Mom\n",
      "Sessions, The\n",
      "Seventh Seal, The\n",
      "Sex and the City\n",
      "Sex, Lies and Videotape\n",
      "Sexual Life\n",
      "Shakespeare in Love\n",
      "Shallow Grave\n",
      "Shame\n",
      "Shampoo\n",
      "Shawshank Redemption, The\n",
      "She's Out of My League\n",
      "Sherlock Holmes\n",
      "Shifty\n",
      "Shining, The\n",
      "Shipping News, The\n",
      "Shivers\n",
      "Shrek\n",
      "Shrek the Third\n",
      "Sicario\n",
      "Sideways\n",
      "Siege, The\n",
      "Signs\n",
      "Silence of the Lambs\n",
      "Silver Bullet\n",
      "Silver Linings Playbook\n",
      "Simone\n",
      "Single White Female\n",
      "Sister Act\n",
      "Six Degrees of Separation\n",
      "Sixth Sense, The\n",
      "Sleepy Hollow\n",
      "Sling Blade\n",
      "Slither\n",
      "Slumdog Millionaire\n",
      "Smashed\n",
      "Smokin' Aces\n",
      "Snow Falling On Cedars\n",
      "Snow White and the Huntsman\n",
      "So I Married an Axe Murderer\n",
      "Social Network, The\n",
      "Solaris\n",
      "Soldier\n",
      "Someone To Watch Over Me\n",
      "Source Code\n",
      "South Park\n",
      "Space Milkshake\n",
      "Spare Me\n",
      "Spartan\n",
      "Speed Racer\n",
      "Sphere\n",
      "Spider-Man\n",
      "St. Elmo's Fire\n",
      "Star Trek\n",
      "Star Trek II: The Wrath of Khan\n",
      "Star Trek: First Contact\n",
      "Star Trek: Generations\n",
      "Star Trek: Nemesis\n",
      "Star Trek: The Motion Picture\n",
      "Star Wars: A New Hope\n",
      "Star Wars: Attack of the Clones\n",
      "Star Wars: Return of the Jedi\n",
      "Star Wars: The Empire Strikes Back\n",
      "Star Wars: The Force Awakens\n",
      "Star Wars: The Phantom Menace\n",
      "Starman\n",
      "Starship Troopers\n",
      "State and Main\n",
      "Station West\n",
      "Stepmom\n",
      "Sting, The\n",
      "Stir of Echoes\n",
      "Storytelling\n",
      "Straight Outta Compton\n",
      "Strange Days\n",
      "Strangers on a Train\n",
      "Stuntman, The\n",
      "Sugar\n",
      "Sugar and Spice\n",
      "Sunset Blvd.\n",
      "Sunshine Cleaning\n",
      "Super 8\n",
      "Superbad\n",
      "Supergirl\n",
      "Surfer King, The\n",
      "Surrogates\n",
      "Suspect Zero\n",
      "Sweeney Todd: The Demon Barber of Fleet Street\n",
      "Sweet Hereafter, The\n",
      "Sweet Smell of Success\n",
      "Swingers\n",
      "Swordfish\n",
      "Synecdoche, New York\n",
      "Syriana\n",
      "Take Shelter\n",
      "Taking of Pelham One Two Three, The\n",
      "Taking Sides\n",
      "Talented Mr. Ripley, The\n",
      "Tall in the Saddle\n",
      "Tamara Drewe\n",
      "Taxi Driver\n",
      "Ted\n",
      "Terminator\n",
      "Terminator 2: Judgement Day\n",
      "Terminator Salvation\n",
      "The Rage: Carrie 2\n",
      "Theory of Everything, The\n",
      "There's Something About Mary\n",
      "They\n",
      "Thing, The\n",
      "Things My Father Never Taught Me, The\n",
      "Thirteen Days\n",
      "This Boy's Life\n",
      "This is 40\n",
      "Thor\n",
      "Thor Ragnarok\n",
      "Three Kings\n",
      "Three Kings (Spoils of War)\n",
      "Three Men and a Baby\n",
      "Three Musketeers, The\n",
      "Thunderbirds\n",
      "Thunderheart\n",
      "Ticker\n",
      "Timber Falls\n",
      "Time Machine, The\n",
      "Tin Cup\n",
      "Tin Men\n",
      "Tinker Tailor Soldier Spy\n",
      "TMNT\n",
      "To Sleep with Anger\n",
      "Tombstone\n",
      "Tomorrow Never Dies\n",
      "Top Gun\n",
      "Total Recall\n",
      "Tourist, The\n",
      "Toy Story\n",
      "Traffic\n",
      "Trainspotting\n",
      "Transformers: The Movie\n",
      "Tremors\n",
      "Tristan and Isolde\n",
      "TRON\n",
      "TRON: Legacy\n",
      "Tropic Thunder\n",
      "True Lies\n",
      "True Romance\n",
      "Truman Show, The\n",
      "Twilight\n",
      "Twilight: New Moon\n",
      "Twin Peaks\n",
      "Twins\n",
      "Two For The Money\n",
      "U Turn\n",
      "Ugly Truth, The\n",
      "Un Singe en Hiver\n",
      "Unbreakable\n",
      "Under Fire\n",
      "Unknown\n",
      "Up\n",
      "Up in the Air\n",
      "Usual Suspects, The\n",
      "V for Vendetta\n",
      "Valkyrie\n",
      "Vanilla Sky\n",
      "Verdict, The\n",
      "Very Bad Things\n",
      "Virtuosity\n",
      "Visitor, The\n",
      "Wag the Dog\n",
      "Walk to Remember, A\n",
      "Walking Tall\n",
      "Wall Street\n",
      "Wall Street: Money Never Sleeps\n",
      "Wall-E\n",
      "Wanted\n",
      "War for the Planet of the Apes\n",
      "War Horse\n",
      "Warm Springs\n",
      "Warrior\n",
      "Watchmen\n",
      "Water for Elephants\n",
      "Way Back, The\n",
      "We Own the Night\n",
      "What Lies Beneath\n",
      "When a Stranger Calls\n",
      "While She Was Out\n",
      "Whistleblower, The\n",
      "White Christmas\n",
      "White Jazz\n",
      "White Ribbon, The\n",
      "White Squall\n",
      "Whiteout\n",
      "Who's Your Daddy\n",
      "Wild At Heart\n",
      "Wild Bunch, The\n",
      "Wild Hogs\n",
      "Wild Things\n",
      "Wild Things: Diamonds in the Rough\n",
      "Wild Wild West\n",
      "Willow\n",
      "Win Win\n",
      "Wind Chill\n",
      "Withnail and I\n",
      "Witness\n",
      "Wizard of Oz, The\n",
      "Wolf of Wall Street, The\n",
      "Wonder Boys\n",
      "Wonder Woman\n",
      "Woodsman, The\n",
      "World is not Enough, The\n",
      "Wrestler, The\n",
      "X-Files: Fight the Future, The\n",
      "X-Men\n",
      "X-Men Origins: Wolverine\n",
      "xXx\n",
      "Year One\n",
      "Yes Man\n",
      "You Can Count On Me\n",
      "You've Got Mail\n",
      "Youth in Revolt\n",
      "Zero Dark Thirty\n",
      "Zerophilia\n",
      "Zootopia\n"
     ]
    }
   ],
   "source": [
    "# Extract unique movie names from the dataframe\n",
    "unique_movies = dialogue_df['movie'].unique()\n",
    "\n",
    "# Print the names of the movies\n",
    "for movie in unique_movies:\n",
    "    print(movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   category        word\n",
      "0         1  compassion\n",
      "1         1     empathy\n",
      "2         1    kindness\n",
      "3         1      caring\n",
      "4         1  generosity\n",
      "\n",
      "Data types of columns:\n",
      "category     int64\n",
      "word        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(moral_dict.head())\n",
    "print(\"\\nData types of columns:\")\n",
    "print(moral_dict.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Movies I've seen\n",
    "- Zootopia\n",
    "- How to Train Your Dragon\n",
    "- How to Train Your Dragon 2\n",
    "- Frozen\n",
    "- Cars 2\n",
    "- Chronicles of Narnia: The Lion, the Witch and the Wardrobe\n",
    "- Interstellar\n",
    "- John Wick\n",
    "- Up\n",
    "- Wall-E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Moral foundations\n",
    "1. Care/Virtue (compassion, empathy, kindness)\n",
    "2. Harm/Vice (harm, suffer, hurt)\n",
    "3. Fairness/Virtue (equality, fairness, justice)\n",
    "4. Cheating/Vice (cheat, unfair, cheating)\n",
    "5. Loyalty/Virtue (loyalty, patriot, team player)\n",
    "6. Betrayal/Vice (traitor, disloyal, treason)\n",
    "7. Authority/Virtue (respect, obey, authority)\n",
    "8. Subversion/Vice (disrespect, disobey, chaos)\n",
    "9. Purity/Virtue (sanctity, sacred, purity)\n",
    "10. Degradation/Vice (impurity, degradation, depravity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering \n",
    "\n",
    "We will try to use simple to advanced methods to cluster the moral of the characters based on their speech\n",
    "\n",
    "Methods to try:\n",
    "- Frequency based clustering\n",
    "- K-means\n",
    "- Autoencoders\n",
    "- BERT-based model\n",
    "- Sentence-BERT\n",
    "- word Embeddings\n",
    "- LLM representation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequency Based Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_category_frequencies(speeches):\n",
    "    category_counts = [0] * 10  # For categories 1-10\n",
    "    total_words = 0\n",
    "    \n",
    "    # Process all speeches\n",
    "    for speech in speeches:\n",
    "        words = speech.lower().split()\n",
    "        total_words += len(words)\n",
    "        \n",
    "        # Count words that appear in moral dictionary\n",
    "        for word in words:\n",
    "            if word in moral_word_dict:\n",
    "                category = moral_word_dict[word]\n",
    "                category_counts[category-1] += 1\n",
    "    \n",
    "    # Calculate frequencies\n",
    "    frequencies = [count/total_words if total_words > 0 else 0 for count in category_counts]\n",
    "    return frequencies, total_words\n",
    "\n",
    "def process_characters(minimum_total_words = 50, movie=\"\" ):\n",
    "    character_categories = []\n",
    "    \n",
    "    if movie:\n",
    "        for character, speeches in dialogue[movie].items():\n",
    "            frequencies, total_words = get_category_frequencies(speeches)\n",
    "            \n",
    "            # Only include characters with substantial dialogue\n",
    "            if total_words >= minimum_total_words:  # Minimum word threshold\n",
    "                dominant_category = np.argmax(frequencies) + 1\n",
    "                character_categories.append({\n",
    "                    'movie': movie,\n",
    "                    'character': character,\n",
    "                    'dominant_category': dominant_category,\n",
    "                    'frequency': frequencies[dominant_category-1],\n",
    "                    'total_words': total_words,\n",
    "                    'all_frequencies': frequencies\n",
    "                })\n",
    "    else:\n",
    "        # Process characters\n",
    "        character_categories = []\n",
    "\n",
    "        for movie, characters in dialogue.items():\n",
    "            for character, speeches in characters.items():\n",
    "                frequencies, total_words = get_category_frequencies(speeches)\n",
    "                \n",
    "                # Only include characters with substantial dialogue\n",
    "                if total_words >= minimum_total_words:  # Minimum word threshold\n",
    "                    dominant_category = np.argmax(frequencies) + 1\n",
    "                    character_categories.append({\n",
    "                        'movie': movie,\n",
    "                        'character': character,\n",
    "                        'dominant_category': dominant_category,\n",
    "                        'frequency': frequencies[dominant_category-1],\n",
    "                        'total_words': total_words,\n",
    "                        'all_frequencies': frequencies\n",
    "                    })\n",
    "\n",
    "    # Group and display results\n",
    "    category_groups = {i: [] for i in range(1, 11)}\n",
    "    for char in character_categories:\n",
    "        category_groups[char['dominant_category']].append(char)\n",
    "\n",
    "    # Print results\n",
    "    for category in range(1, 11):\n",
    "        chars = category_groups[category]\n",
    "        if chars:\n",
    "            print(f\"\\nMoral Category {category}:\")\n",
    "            print(f\"Total characters: {len(chars)}\")\n",
    "            \n",
    "            # Sort just the top 5\n",
    "            top_chars = sorted(chars, key=lambda x: x['frequency'], reverse=True)[:5]\n",
    "            print(\"\\nTop characters:\")\n",
    "            for char in top_chars:\n",
    "                print(f\"- {char['character']} from {char['movie']}\")\n",
    "                print(f\"  Frequency: {char['frequency']:.5f}\")\n",
    "    \n",
    "    return character_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' I wish I could be with you on this very special day but... my clutch assembly broke. You know how it is. ',\n",
       " \" We are here to celebrate. Today all your hard work pays off. The world turned their backs on cars like us. They stopped manufacturing us, stopped making our parts. The only thing they haven't stopped doing is laughing at us. They've called us terrible names... \",\n",
       " ' Jalopy. Rustbucket. ',\n",
       " ' Heap. Clunker. ',\n",
       " ' Junker, beater, wreck. ',\n",
       " ' Rattletrap. ',\n",
       " ' Lemon. But their insults just give us strength. Because today, my friends... ',\n",
       " ' ...that all ends. ',\n",
       " \" They laughed at us. But now it's our turn to laugh back. \",\n",
       " ' Embrace your inner lemon! Let it drive you! ',\n",
       " \" This was meant to be alternative fuel's greatest moment. \",\n",
       " ' After today everyone will race back to gasoline. ',\n",
       " \" And we, the owners of the world's largest untapped oil reserve, will become the most powerful cars in the world! \",\n",
       " ' They will come to us and they will have no choice, `cause they will need us. ',\n",
       " ' And they will finally respect us. So hold your hoods high. After today you will never again be ashamed of who you are! ',\n",
       " ' Long live Lemons! 91. ']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogue[\"Cars 2\"][\"ENGINE VOICE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Moral Category 1:\n",
      "Total characters: 8\n",
      "\n",
      "Top characters:\n",
      "- JUDY from Zootopia\n",
      "  Frequency: 0.01190\n",
      "- LIONHEART from Zootopia\n",
      "  Frequency: 0.00797\n",
      "- DUKE WEASELTON from Zootopia\n",
      "  Frequency: 0.00637\n",
      "- BELLWETHER from Zootopia\n",
      "  Frequency: 0.00370\n",
      "- HOPPS from Zootopia\n",
      "  Frequency: 0.00341\n",
      "\n",
      "Moral Category 2:\n",
      "Total characters: 2\n",
      "\n",
      "Top characters:\n",
      "- GAZELLE from Zootopia\n",
      "  Frequency: 0.00877\n",
      "- GIDEON GREY from Zootopia\n",
      "  Frequency: 0.00621\n",
      "\n",
      "Moral Category 3:\n",
      "Total characters: 1\n",
      "\n",
      "Top characters:\n",
      "- MR from Zootopia\n",
      "  Frequency: 0.00755\n",
      "\n",
      "Moral Category 4:\n",
      "Total characters: 1\n",
      "\n",
      "Top characters:\n",
      "- BOGO from Zootopia\n",
      "  Frequency: 0.00173\n",
      "\n",
      "Moral Category 5:\n",
      "Total characters: 1\n",
      "\n",
      "Top characters:\n",
      "- YOUNG JUDY from Zootopia\n",
      "  Frequency: 0.00472\n",
      "\n",
      "Moral Category 7:\n",
      "Total characters: 1\n",
      "\n",
      "Top characters:\n",
      "- BONNIE HOPPS from Zootopia\n",
      "  Frequency: 0.01158\n",
      "\n",
      "Moral Category 9:\n",
      "Total characters: 1\n",
      "\n",
      "Top characters:\n",
      "- STU HOPPS from Zootopia\n",
      "  Frequency: 0.00471\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'movie': 'Zootopia',\n",
       "  'character': 'YOUNG JUDY',\n",
       "  'dominant_category': np.int64(5),\n",
       "  'frequency': 0.0047169811320754715,\n",
       "  'total_words': 212,\n",
       "  'all_frequencies': [0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0047169811320754715,\n",
       "   0.0,\n",
       "   0.0047169811320754715,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0]},\n",
       " {'movie': 'Zootopia',\n",
       "  'character': 'GIDEON GREY',\n",
       "  'dominant_category': np.int64(2),\n",
       "  'frequency': 0.006211180124223602,\n",
       "  'total_words': 161,\n",
       "  'all_frequencies': [0.0,\n",
       "   0.006211180124223602,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0]},\n",
       " {'movie': 'Zootopia',\n",
       "  'character': 'STU HOPPS',\n",
       "  'dominant_category': np.int64(9),\n",
       "  'frequency': 0.004705882352941176,\n",
       "  'total_words': 425,\n",
       "  'all_frequencies': [0.002352941176470588,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.002352941176470588,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.002352941176470588,\n",
       "   0.0,\n",
       "   0.004705882352941176,\n",
       "   0.0]},\n",
       " {'movie': 'Zootopia',\n",
       "  'character': 'BONNIE HOPPS',\n",
       "  'dominant_category': np.int64(7),\n",
       "  'frequency': 0.011583011583011582,\n",
       "  'total_words': 259,\n",
       "  'all_frequencies': [0.007722007722007722,\n",
       "   0.003861003861003861,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.011583011583011582,\n",
       "   0.0,\n",
       "   0.003861003861003861,\n",
       "   0.0]},\n",
       " {'movie': 'Zootopia',\n",
       "  'character': 'LIONHEART',\n",
       "  'dominant_category': np.int64(1),\n",
       "  'frequency': 0.00796812749003984,\n",
       "  'total_words': 251,\n",
       "  'all_frequencies': [0.00796812749003984,\n",
       "   0.00398406374501992,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.00796812749003984,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0]},\n",
       " {'movie': 'Zootopia',\n",
       "  'character': 'BELLWETHER',\n",
       "  'dominant_category': np.int64(1),\n",
       "  'frequency': 0.0036968576709796672,\n",
       "  'total_words': 541,\n",
       "  'all_frequencies': [0.0036968576709796672,\n",
       "   0.0018484288354898336,\n",
       "   0.0018484288354898336,\n",
       "   0.0,\n",
       "   0.0036968576709796672,\n",
       "   0.0,\n",
       "   0.0018484288354898336,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0]},\n",
       " {'movie': 'Zootopia',\n",
       "  'character': 'JUDY',\n",
       "  'dominant_category': np.int64(1),\n",
       "  'frequency': 0.011904761904761904,\n",
       "  'total_words': 84,\n",
       "  'all_frequencies': [0.011904761904761904,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0]},\n",
       " {'movie': 'Zootopia',\n",
       "  'character': 'GAZELLE',\n",
       "  'dominant_category': np.int64(2),\n",
       "  'frequency': 0.008771929824561403,\n",
       "  'total_words': 114,\n",
       "  'all_frequencies': [0.0,\n",
       "   0.008771929824561403,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0]},\n",
       " {'movie': 'Zootopia',\n",
       "  'character': 'HOPPS',\n",
       "  'dominant_category': np.int64(1),\n",
       "  'frequency': 0.0034094783498124785,\n",
       "  'total_words': 2933,\n",
       "  'all_frequencies': [0.0034094783498124785,\n",
       "   0.002045687009887487,\n",
       "   0.00034094783498124785,\n",
       "   0.0006818956699624957,\n",
       "   0.0006818956699624957,\n",
       "   0.0,\n",
       "   0.0006818956699624957,\n",
       "   0.0,\n",
       "   0.00034094783498124785,\n",
       "   0.0006818956699624957]},\n",
       " {'movie': 'Zootopia',\n",
       "  'character': 'CLAWHAUSER',\n",
       "  'dominant_category': np.int64(1),\n",
       "  'frequency': 0.003125,\n",
       "  'total_words': 320,\n",
       "  'all_frequencies': [0.003125,\n",
       "   0.003125,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.003125,\n",
       "   0.0,\n",
       "   0.003125,\n",
       "   0.0,\n",
       "   0.003125,\n",
       "   0.0]},\n",
       " {'movie': 'Zootopia',\n",
       "  'character': 'BOGO',\n",
       "  'dominant_category': np.int64(4),\n",
       "  'frequency': 0.0017271157167530224,\n",
       "  'total_words': 579,\n",
       "  'all_frequencies': [0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0017271157167530224,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0017271157167530224,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0017271157167530224]},\n",
       " {'movie': 'Zootopia',\n",
       "  'character': 'NICK',\n",
       "  'dominant_category': np.int64(1),\n",
       "  'frequency': 0.0034028073160357296,\n",
       "  'total_words': 2351,\n",
       "  'all_frequencies': [0.0034028073160357296,\n",
       "   0.0004253509145044662,\n",
       "   0.0,\n",
       "   0.0008507018290089324,\n",
       "   0.0004253509145044662,\n",
       "   0.0,\n",
       "   0.0008507018290089324,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0004253509145044662]},\n",
       " {'movie': 'Zootopia',\n",
       "  'character': 'DUKE WEASELTON',\n",
       "  'dominant_category': np.int64(1),\n",
       "  'frequency': 0.006369426751592357,\n",
       "  'total_words': 157,\n",
       "  'all_frequencies': [0.006369426751592357,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.006369426751592357,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.006369426751592357]},\n",
       " {'movie': 'Zootopia',\n",
       "  'character': 'FLASH',\n",
       "  'dominant_category': np.int64(1),\n",
       "  'frequency': 0.0,\n",
       "  'total_words': 70,\n",
       "  'all_frequencies': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]},\n",
       " {'movie': 'Zootopia',\n",
       "  'character': 'MR',\n",
       "  'dominant_category': np.int64(3),\n",
       "  'frequency': 0.007547169811320755,\n",
       "  'total_words': 265,\n",
       "  'all_frequencies': [0.0037735849056603774,\n",
       "   0.0,\n",
       "   0.007547169811320755,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.007547169811320755,\n",
       "   0.0,\n",
       "   0.0]}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the function\n",
    "process_characters(50, \"Zootopia\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# 1. Load BERT model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = AutoModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# 2. Create training data from moral dictionary\n",
    "def create_moral_examples():\n",
    "    # Group words by category\n",
    "    category_words = defaultdict(list)\n",
    "    for _, row in moral_dict.iterrows():\n",
    "        category_words[row['category']].append(row['word'])\n",
    "    return category_words\n",
    "\n",
    "# 3. Function to get BERT embeddings\n",
    "def get_bert_embedding(text):\n",
    "    # Tokenize and get BERT embeddings\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    # Use [CLS] token embedding (first token)\n",
    "    return outputs.last_hidden_state[:, 0, :].numpy()\n",
    "\n",
    "# 4. Process characters\n",
    "def embedding(movie=\"\", minimum_total_speech=0):\n",
    "    character_embeddings = []\n",
    "    character_info = []\n",
    "\n",
    "    if movie:\n",
    "        characters = dialogue[movie]\n",
    "        for character, speeches in characters.items():\n",
    "            if len(speeches) >= minimum_total_speech:  # Minimum dialogue threshold\n",
    "                # Process each speech\n",
    "                speech_embeddings = []\n",
    "                for speech in speeches:\n",
    "                    embedding = get_bert_embedding(speech)\n",
    "                    speech_embeddings.append(embedding[0])  # Remove batch dimension\n",
    "                \n",
    "                # Average embeddings for the character\n",
    "                character_embedding = np.mean(speech_embeddings, axis=0)\n",
    "                character_embeddings.append(character_embedding)\n",
    "                character_info.append((movie, character))\n",
    "    else:\n",
    "        for movie, characters in dialogue.items():\n",
    "            for character, speeches in characters.items():\n",
    "                if len(speeches) >= minimum_total_speech:  # Minimum dialogue threshold\n",
    "                    # Process each speech\n",
    "                    speech_embeddings = []\n",
    "                    for speech in speeches:\n",
    "                        embedding = get_bert_embedding(speech)\n",
    "                        speech_embeddings.append(embedding[0])  # Remove batch dimension\n",
    "                    \n",
    "                    # Average embeddings for the character\n",
    "                    character_embedding = np.mean(speech_embeddings, axis=0)\n",
    "                    character_embeddings.append(character_embedding)\n",
    "                    character_info.append((movie, character))\n",
    "    \n",
    "    print(f\"Total characters: {len(character_embeddings)}\")\n",
    "\n",
    "    # 5. Create moral category centroids\n",
    "    moral_categories = create_moral_examples()\n",
    "    category_centroids = {}\n",
    "\n",
    "    for category, words in moral_categories.items():\n",
    "        # Get embeddings for each word in category\n",
    "        word_embeddings = []\n",
    "        for word in words:\n",
    "            embedding = get_bert_embedding(word)\n",
    "            word_embeddings.append(embedding[0])\n",
    "        \n",
    "        # Average to get category centroid\n",
    "        category_centroids[category] = np.mean(word_embeddings, axis=0)\n",
    "    \n",
    "    return character_embeddings, character_info, category_centroids\n",
    "\n",
    "# 6. Assign characters to categories\n",
    "def assign_category(embedding, centroids):\n",
    "    # Calculate distance to each centroid\n",
    "    distances = {}\n",
    "    for category, centroid in centroids.items():\n",
    "        distance = np.linalg.norm(embedding - centroid)\n",
    "        distances[category] = distance\n",
    "    \n",
    "    # Return category with minimum distance\n",
    "    return min(distances.items(), key=lambda x: x[1])[0]\n",
    "\n",
    "def classify_categories(character_embeddings, character_info, category_centroids):\n",
    "    # 7. Classify characters\n",
    "    character_categories = []\n",
    "    for idx, embedding in enumerate(character_embeddings):\n",
    "        movie, character = character_info[idx]\n",
    "        category = assign_category(embedding, category_centroids)\n",
    "        character_categories.append({\n",
    "            'movie': movie,\n",
    "            'character': character,\n",
    "            'category': category\n",
    "        })\n",
    "\n",
    "    # 8. Analyze results\n",
    "    for category in range(1, 11):\n",
    "        chars = [c for c in character_categories if c['category'] == category]\n",
    "        if chars:\n",
    "            print(f\"\\nMoral Category {category}:\")\n",
    "            print(f\"Total characters: {len(chars)}\")\n",
    "            print(\"\\nExample characters:\")\n",
    "            for char in chars[:5]:\n",
    "                print(f\"- {char['character']} from {char['movie']}\")\n",
    "\n",
    "def cluster_characters_bert(movie=\"\", minimum_total_speech=0):\n",
    "    # Get character embeddings and moral category centroids\n",
    "    character_embeddings, character_info, category_centroids = embedding(movie, minimum_total_speech)\n",
    "    \n",
    "    # Classify characters into moral categories\n",
    "    classify_categories(character_embeddings, character_info, category_centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 19\n",
      "[{'movie': 'Cars 2', 'character': 'FINN', 'category': 7}, {'movie': 'Cars 2', 'character': 'PROFESSOR ZUNDAPP', 'category': 2}, {'movie': 'Cars 2', 'character': 'GREM', 'category': 7}, {'movie': 'Cars 2', 'character': 'ACER', 'category': 4}, {'movie': 'Cars 2', 'character': 'MATER', 'category': 10}, {'movie': 'Cars 2', 'character': 'OTIS', 'category': 10}, {'movie': 'Cars 2', 'character': 'LUIGI', 'category': 10}, {'movie': 'Cars 2', 'character': 'MCQUEEN', 'category': 8}, {'movie': 'Cars 2', 'character': 'SALLY', 'category': 1}, {'movie': 'Cars 2', 'character': 'MEL DORADO', 'category': 7}, {'movie': 'Cars 2', 'character': 'MILES AXLEROD', 'category': 4}, {'movie': 'Cars 2', 'character': 'FRANCESCO', 'category': 2}, {'movie': 'Cars 2', 'character': 'HOLLEY', 'category': 7}, {'movie': 'Cars 2', 'character': 'BRENT MUSTANGBURGER', 'category': 7}, {'movie': 'Cars 2', 'character': 'DAVID HOBBSCAP', 'category': 7}, {'movie': 'Cars 2', 'character': 'DARRELL CARTRIP', 'category': 4}, {'movie': 'Cars 2', 'character': 'TOMBER', 'category': 10}, {'movie': 'Cars 2', 'character': 'UNCLE TOPOLINO', 'category': 6}, {'movie': 'Cars 2', 'character': 'ENGINE VOICE', 'category': 10}]\n",
      "\n",
      "Moral Category 1:\n",
      "Total characters: 1\n",
      "\n",
      "Example characters:\n",
      "- SALLY from Cars 2\n",
      "\n",
      "Moral Category 2:\n",
      "Total characters: 2\n",
      "\n",
      "Example characters:\n",
      "- PROFESSOR ZUNDAPP from Cars 2\n",
      "- FRANCESCO from Cars 2\n",
      "\n",
      "Moral Category 4:\n",
      "Total characters: 3\n",
      "\n",
      "Example characters:\n",
      "- ACER from Cars 2\n",
      "- MILES AXLEROD from Cars 2\n",
      "- DARRELL CARTRIP from Cars 2\n",
      "\n",
      "Moral Category 6:\n",
      "Total characters: 1\n",
      "\n",
      "Example characters:\n",
      "- UNCLE TOPOLINO from Cars 2\n",
      "\n",
      "Moral Category 7:\n",
      "Total characters: 6\n",
      "\n",
      "Example characters:\n",
      "- FINN from Cars 2\n",
      "- GREM from Cars 2\n",
      "- MEL DORADO from Cars 2\n",
      "- HOLLEY from Cars 2\n",
      "- BRENT MUSTANGBURGER from Cars 2\n",
      "\n",
      "Moral Category 8:\n",
      "Total characters: 1\n",
      "\n",
      "Example characters:\n",
      "- MCQUEEN from Cars 2\n",
      "\n",
      "Moral Category 10:\n",
      "Total characters: 5\n",
      "\n",
      "Example characters:\n",
      "- MATER from Cars 2\n",
      "- OTIS from Cars 2\n",
      "- LUIGI from Cars 2\n",
      "- TOMBER from Cars 2\n",
      "- ENGINE VOICE from Cars 2\n"
     ]
    }
   ],
   "source": [
    "cluster_characters_bert(\"Cars 2\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentence-BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# 1. Load SBERT model\n",
    "sbert_model = SentenceTransformer('all-mpnet-base-v2')  # Better performance than base BERTe BERTe BERT\n",
    "\n",
    "# 2. Create training data from moral dictionary\n",
    "def create_moral_examples():\n",
    "    category_words = defaultdict(list)\n",
    "    for _, row in moral_dict.iterrows():\n",
    "        category_words[row['category']].append(row['word'])\n",
    "    return category_words\n",
    "\n",
    "# 3. Process characters\n",
    "def embedding(movie=\"\", minimum_total_speech=0):\n",
    "    character_embeddings = []\n",
    "    character_info = []\n",
    "\n",
    "    if movie:\n",
    "        characters = dialogue[movie]\n",
    "        for character, speeches in characters.items():\n",
    "            if len(speeches) >= minimum_total_speech:  # Minimum dialogue threshold\n",
    "                # Process all speeches at once (SBERT is optimized for batch processing)\n",
    "                speech_embeddings = sbert_model.encode(speeches)\n",
    "                \n",
    "                # Average embeddings for the character\n",
    "                character_embedding = np.mean(speech_embeddings, axis=0)\n",
    "                character_embeddings.append(character_embedding)\n",
    "                character_info.append((movie, character))\n",
    "    else:\n",
    "        for movie, characters in dialogue.items():\n",
    "            for character, speeches in characters.items():\n",
    "                if len(speeches) >= minimum_total_speech:  # Minimum dialogue threshold\n",
    "                    # Process all speeches at once (SBERT is optimized for batch processing)\n",
    "                    speech_embeddings = sbert_model.encode(speeches)\n",
    "                    \n",
    "                    # Average embeddings for the character\n",
    "                    character_embedding = np.mean(speech_embeddings, axis=0)\n",
    "                    character_embeddings.append(character_embedding)\n",
    "                    character_info.append((movie, character))\n",
    "\n",
    "    print(f\"Total characters: {len(character_embeddings)}\")\n",
    "\n",
    "    # 4. Create moral category centroids\n",
    "    moral_categories = create_moral_examples()\n",
    "    category_centroids = {}\n",
    "\n",
    "    for category, words in moral_categories.items():\n",
    "        # Encode all words in category at once\n",
    "        word_embeddings = sbert_model.encode(words)\n",
    "        \n",
    "        # Average to get category centroid\n",
    "        category_centroids[category] = np.mean(word_embeddings, axis=0)\n",
    "    \n",
    "    return character_embeddings, character_info, category_centroids\n",
    "\n",
    "# 5. Assign characters to categories\n",
    "def assign_category(embedding, centroids):\n",
    "    # Calculate cosine similarity instead of Euclidean distance\n",
    "    similarities = {}\n",
    "    for category, centroid in centroids.items():\n",
    "        similarity = np.dot(embedding, centroid) / (np.linalg.norm(embedding) * np.linalg.norm(centroid))\n",
    "        similarities[category] = similarity\n",
    "    \n",
    "    # Return category with highest similarity\n",
    "    return max(similarities.items(), key=lambda x: x[1])[0]\n",
    "\n",
    "\n",
    "def classify_categories(character_embeddings, character_info, category_centroids):\n",
    "\n",
    "    # 6. Assign characters to categories\n",
    "    character_categories = []\n",
    "    for idx, embedding in enumerate(character_embeddings):\n",
    "        movie, character = character_info[idx]\n",
    "        category = assign_category(embedding, category_centroids)\n",
    "        character_categories.append({\n",
    "            'movie': movie,\n",
    "            'character': character,\n",
    "            'category': category\n",
    "        })\n",
    "\n",
    "    # 7. Analyze results\n",
    "    for category in range(1, 11):\n",
    "        chars = [c for c in character_categories if c['category'] == category]\n",
    "        if chars:\n",
    "            print(f\"\\nMoral Category {category}:\")\n",
    "            print(f\"Total characters: {len(chars)}\")\n",
    "            print(\"\\nExample characters:\")\n",
    "            for char in chars[:5]:\n",
    "                print(f\"- {char['character']} from {char['movie']}\")\n",
    "\n",
    "def cluster_characters_sbert(movie=\"\", minimum_total_speech=0):\n",
    "    # Get character embeddings and moral category centroids\n",
    "    character_embeddings, character_info, category_centroids = embedding(movie, minimum_total_speech)\n",
    "    \n",
    "    # Classify characters into moral categories\n",
    "    classify_categories(character_embeddings, character_info, category_centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 19\n",
      "[{'movie': 'Cars 2', 'character': 'FINN', 'category': 7}, {'movie': 'Cars 2', 'character': 'PROFESSOR ZUNDAPP', 'category': 2}, {'movie': 'Cars 2', 'character': 'GREM', 'category': 7}, {'movie': 'Cars 2', 'character': 'ACER', 'category': 4}, {'movie': 'Cars 2', 'character': 'MATER', 'category': 10}, {'movie': 'Cars 2', 'character': 'OTIS', 'category': 10}, {'movie': 'Cars 2', 'character': 'LUIGI', 'category': 10}, {'movie': 'Cars 2', 'character': 'MCQUEEN', 'category': 8}, {'movie': 'Cars 2', 'character': 'SALLY', 'category': 1}, {'movie': 'Cars 2', 'character': 'MEL DORADO', 'category': 7}, {'movie': 'Cars 2', 'character': 'MILES AXLEROD', 'category': 4}, {'movie': 'Cars 2', 'character': 'FRANCESCO', 'category': 2}, {'movie': 'Cars 2', 'character': 'HOLLEY', 'category': 7}, {'movie': 'Cars 2', 'character': 'BRENT MUSTANGBURGER', 'category': 7}, {'movie': 'Cars 2', 'character': 'DAVID HOBBSCAP', 'category': 7}, {'movie': 'Cars 2', 'character': 'DARRELL CARTRIP', 'category': 4}, {'movie': 'Cars 2', 'character': 'TOMBER', 'category': 10}, {'movie': 'Cars 2', 'character': 'UNCLE TOPOLINO', 'category': 6}, {'movie': 'Cars 2', 'character': 'ENGINE VOICE', 'category': 10}]\n",
      "\n",
      "Moral Category 1:\n",
      "Total characters: 1\n",
      "\n",
      "Example characters:\n",
      "- SALLY from Cars 2\n",
      "\n",
      "Moral Category 2:\n",
      "Total characters: 2\n",
      "\n",
      "Example characters:\n",
      "- PROFESSOR ZUNDAPP from Cars 2\n",
      "- FRANCESCO from Cars 2\n",
      "\n",
      "Moral Category 4:\n",
      "Total characters: 3\n",
      "\n",
      "Example characters:\n",
      "- ACER from Cars 2\n",
      "- MILES AXLEROD from Cars 2\n",
      "- DARRELL CARTRIP from Cars 2\n",
      "\n",
      "Moral Category 6:\n",
      "Total characters: 1\n",
      "\n",
      "Example characters:\n",
      "- UNCLE TOPOLINO from Cars 2\n",
      "\n",
      "Moral Category 7:\n",
      "Total characters: 6\n",
      "\n",
      "Example characters:\n",
      "- FINN from Cars 2\n",
      "- GREM from Cars 2\n",
      "- MEL DORADO from Cars 2\n",
      "- HOLLEY from Cars 2\n",
      "- BRENT MUSTANGBURGER from Cars 2\n",
      "\n",
      "Moral Category 8:\n",
      "Total characters: 1\n",
      "\n",
      "Example characters:\n",
      "- MCQUEEN from Cars 2\n",
      "\n",
      "Moral Category 10:\n",
      "Total characters: 5\n",
      "\n",
      "Example characters:\n",
      "- MATER from Cars 2\n",
      "- OTIS from Cars 2\n",
      "- LUIGI from Cars 2\n",
      "- TOMBER from Cars 2\n",
      "- ENGINE VOICE from Cars 2\n"
     ]
    }
   ],
   "source": [
    "cluster_characters_sbert(\"Cars 2\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auto-encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# 1. Load SBERT model\n",
    "model = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "def cluster_characters_sbert_autoencoder(movie=\"\", minimum_total_speech=0):\n",
    "    # 2. Get character embeddings\n",
    "    character_embeddings = []\n",
    "    character_info = []\n",
    "\n",
    "    if movie:\n",
    "        characters = dialogue[movie]\n",
    "        for character, speeches in characters.items():\n",
    "            if len(speeches) >= minimum_total_speech:  # Minimum dialogue threshold\n",
    "                # Process all speeches at once (SBERT is optimized for batch processing)\n",
    "                speech_embeddings = sbert_model.encode(speeches)\n",
    "                \n",
    "                # Average embeddings for the character\n",
    "                character_embedding = np.mean(speech_embeddings, axis=0)\n",
    "                character_embeddings.append(character_embedding)\n",
    "                character_info.append((movie, character))\n",
    "    else:\n",
    "        for movie, characters in dialogue.items():\n",
    "            for character, speeches in characters.items():\n",
    "                if len(speeches) >= minimum_total_speech:  # Minimum dialogue threshold\n",
    "                    # Process all speeches at once (SBERT is optimized for batch processing)\n",
    "                    speech_embeddings = sbert_model.encode(speeches)\n",
    "                    \n",
    "                    # Average embeddings for the character\n",
    "                    character_embedding = np.mean(speech_embeddings, axis=0)\n",
    "                    character_embeddings.append(character_embedding)\n",
    "                    character_info.append((movie, character))\n",
    "\n",
    "        print(f\"Total characters: {len(character_embeddings)}\")\n",
    "\n",
    "    # 1. Process moral dictionary first\n",
    "    moral_categories = defaultdict(list)\n",
    "    for _, row in moral_dict.iterrows():\n",
    "        moral_categories[row['category']].append(row['word'])\n",
    "\n",
    "    # Get embeddings for moral dictionary words\n",
    "    category_embeddings = {}\n",
    "    for category, words in moral_categories.items():\n",
    "        word_embeddings = model.encode(words)  # Shape: (num_words, 768)\n",
    "        category_embedding = np.mean(word_embeddings, axis=0)  # Shape: (768,)\n",
    "        category_embeddings[category] = category_embedding\n",
    "\n",
    "    # Create a tensor of all category embeddings\n",
    "    category_embeddings_tensor = torch.FloatTensor(list(category_embeddings.values()))  # Shape: (10, 768)\n",
    "\n",
    "    # 2. Create dataset class with both character embeddings and moral category embeddings\n",
    "    class MoralDataset(Dataset):\n",
    "        def __init__(self, char_embeddings, category_embeddings):\n",
    "            self.char_embeddings = torch.FloatTensor(char_embeddings)\n",
    "            self.category_embeddings = torch.FloatTensor(list(category_embeddings.values()))\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.char_embeddings)\n",
    "        \n",
    "        def __getitem__(self, idx):\n",
    "            return self.char_embeddings[idx], self.category_embeddings\n",
    "\n",
    "    # 3. Modified autoencoder to consider moral categories\n",
    "    class MoralAutoencoder(nn.Module):\n",
    "        def __init__(self, input_dim, num_categories=10):\n",
    "            super(MoralAutoencoder, self).__init__()\n",
    "            \n",
    "            self.encoder = nn.Sequential(\n",
    "                nn.Linear(input_dim, 256),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(256, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(128, num_categories)  # Output dimension matches number of moral categories\n",
    "            )\n",
    "            \n",
    "            self.decoder = nn.Sequential(\n",
    "                nn.Linear(num_categories, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(128, 256),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(256, input_dim)\n",
    "            )\n",
    "        \n",
    "        def forward(self, x):\n",
    "            encoded = self.encoder(x)\n",
    "            decoded = self.decoder(encoded)\n",
    "            return encoded, decoded\n",
    "\n",
    "    def moral_loss(decoded, original, encoded, category_embeddings_tensor):\n",
    "        reconstruction_loss = nn.MSELoss()(decoded, original)\n",
    "        \n",
    "        # Moral category alignment loss using category_embeddings_tensor\n",
    "        moral_loss = 0\n",
    "        for i in range(encoded.size(0)):\n",
    "            similarities = torch.matmul(encoded[i], category_embeddings_tensor)\n",
    "            moral_loss += -torch.log_softmax(similarities, dim=0).mean()\n",
    "        \n",
    "        return reconstruction_loss + moral_loss\n",
    "    \n",
    "    # 5. Training process\n",
    "    input_dim = character_embeddings[0].shape[0]\n",
    "    autoencoder = MoralAutoencoder(input_dim)\n",
    "    optimizer = optim.Adam(autoencoder.parameters())\n",
    "\n",
    "    dataset = MoralDataset(character_embeddings, category_embeddings)\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    # Training loop\n",
    "    n_epochs = 100\n",
    "    for epoch in range(n_epochs):\n",
    "        total_loss = 0\n",
    "        for batch_chars, batch_categories in dataloader:\n",
    "            # Forward pass\n",
    "            encoded, decoded = autoencoder(batch_chars)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = moral_loss(decoded, batch_chars, encoded, batch_categories)\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{n_epochs}], Loss: {total_loss/len(dataloader):.4f}')\n",
    "\n",
    "    # 6. Get encodings and classify\n",
    "    autoencoder.eval()\n",
    "    character_categories = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, embedding in enumerate(character_embeddings):\n",
    "            embedding_tensor = torch.FloatTensor(embedding)\n",
    "            encoded, _ = autoencoder(embedding_tensor)\n",
    "            \n",
    "            # Use category_embeddings_tensor for comparison\n",
    "            # encoded shape: (1, 10)\n",
    "            # category_embeddings_tensor shape: (10, 768)\n",
    "            similarities = torch.matmul(encoded, category_embeddings_tensor)\n",
    "            best_category = int(torch.argmax(similarities)) + 1\n",
    "            \n",
    "            character_categories.append({\n",
    "                'movie': character_info[idx][0],\n",
    "                'character': character_info[idx][1],\n",
    "                'category': best_category,\n",
    "                'confidence': float(torch.max(similarities))\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4p/8nlm0n094791rk0xf6jzk8ch0000gn/T/ipykernel_63460/479768360.py:97: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3687.)\n",
      "  similarities = torch.matmul(encoded[i], category_embeddings.T)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 126.2323\n",
      "Epoch [20/100], Loss: 126.2322\n",
      "Epoch [30/100], Loss: 126.2321\n",
      "Epoch [40/100], Loss: 126.2321\n",
      "Epoch [50/100], Loss: 126.2321\n",
      "Epoch [60/100], Loss: 126.2321\n",
      "Epoch [70/100], Loss: 126.2321\n",
      "Epoch [80/100], Loss: 126.2321\n",
      "Epoch [90/100], Loss: 126.2321\n",
      "Epoch [100/100], Loss: 126.2321\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x10 and 768x10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[96], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcluster_characters_sbert_autoencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCars 2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[95], line 141\u001b[0m, in \u001b[0;36mcluster_characters_sbert_autoencoder\u001b[0;34m(movie, minimum_total_speech)\u001b[0m\n\u001b[1;32m    138\u001b[0m encoded, _ \u001b[38;5;241m=\u001b[39m autoencoder(embedding_tensor)\n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m# Compare with moral category embeddings\u001b[39;00m\n\u001b[0;32m--> 141\u001b[0m similarities \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFloatTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcategory_embeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m best_category \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(torch\u001b[38;5;241m.\u001b[39margmax(similarities)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    144\u001b[0m character_categories\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmovie\u001b[39m\u001b[38;5;124m'\u001b[39m: character_info[idx][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcharacter\u001b[39m\u001b[38;5;124m'\u001b[39m: character_info[idx][\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m: best_category,\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfidence\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(torch\u001b[38;5;241m.\u001b[39mmax(similarities))\n\u001b[1;32m    149\u001b[0m })\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x10 and 768x10)"
     ]
    }
   ],
   "source": [
    "cluster_characters_sbert_autoencoder(\"Cars 2\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
